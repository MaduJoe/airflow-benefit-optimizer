# ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

## ğŸš¨ ì¼ë°˜ì ì¸ ë¬¸ì œ ë° í•´ê²°ì±…

### 1ï¸âƒ£ DAG ê´€ë ¨ ë¬¸ì œ

#### DAGê°€ UIì— ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŒ
**ì¦ìƒ**: Airflow UIì—ì„œ `ajd_benefit_optimizer` DAGë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ

**ì›ì¸ ë° í•´ê²°ì±…**:
```bash
# 1. AIRFLOW_HOME ê²½ë¡œ í™•ì¸
echo $AIRFLOW_HOME
export AIRFLOW_HOME=/mnt/c/Users/jaeke/ajungdang/airflow-home

# 2. DAG íŒŒì¼ ê²½ë¡œ í™•ì¸
ls -la $AIRFLOW_HOME/dags/ajd_benefit_optimizer.py

# 3. Python êµ¬ë¬¸ ì˜¤ë¥˜ ì²´í¬
python $AIRFLOW_HOME/dags/ajd_benefit_optimizer.py

# 4. PYTHONPATH ì„¤ì •
export PYTHONPATH=$AIRFLOW_HOME/dags:$PYTHONPATH

# 5. DAG ëª©ë¡ ìƒˆë¡œê³ ì¹¨
airflow dags list | grep ajd
```

#### ImportError: No module named 'lib'
**ì¦ìƒ**: `ModuleNotFoundError: No module named 'lib'`

**í•´ê²°ì±…**:
```bash
# 1. Python ê²½ë¡œ ì„¤ì •
export PYTHONPATH=$AIRFLOW_HOME/dags:$PYTHONPATH

# 2. lib ë””ë ‰í† ë¦¬ í™•ì¸
ls -la $AIRFLOW_HOME/dags/lib/

# 3. __init__.py íŒŒì¼ í™•ì¸
ls -la $AIRFLOW_HOME/dags/lib/__init__.py

# 4. ê¶Œí•œ í™•ì¸ ë° ìˆ˜ì •
chmod +x $AIRFLOW_HOME/dags/lib/*.py
```

#### DAG êµ¬ë¬¸ ì˜¤ë¥˜
**ì¦ìƒ**: DAGê°€ ë¡œë“œë˜ì§€ ì•Šê±°ë‚˜ ì˜¤ë¥˜ í‘œì‹œ

**ë””ë²„ê¹… ë°©ë²•**:
```bash
# 1. ì§ì ‘ Python ì‹¤í–‰
cd $AIRFLOW_HOME
python dags/ajd_benefit_optimizer.py

# 2. êµ¬ë¬¸ ê²€ì‚¬
python -m py_compile dags/ajd_benefit_optimizer.py

# 3. import í…ŒìŠ¤íŠ¸
python -c "from dags.lib import io_utils, rules, scoring"

# 4. Airflowì—ì„œ êµ¬ë¬¸ ì²´í¬
airflow dags show ajd_benefit_optimizer
```

### 2ï¸âƒ£ ì‹¤í–‰ ê´€ë ¨ ë¬¸ì œ

#### íƒœìŠ¤í¬ ì‹¤í–‰ ì‹¤íŒ¨
**ì¦ìƒ**: íŠ¹ì • íƒœìŠ¤í¬ê°€ ì‹¤íŒ¨í•˜ê³  ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ

**ë¡œê·¸ í™•ì¸**:
```bash
# 1. íƒœìŠ¤í¬ ë¡œê·¸ í™•ì¸
airflow tasks logs ajd_benefit_optimizer <task_id> $(date +%Y-%m-%d) 1

# 2. ì „ì²´ DAG ì‹¤í–‰ ìƒíƒœ
airflow dags state ajd_benefit_optimizer $(date +%Y-%m-%d)

# 3. ì‹¤íŒ¨í•œ íƒœìŠ¤í¬ ì¬ì‹¤í–‰
airflow tasks run ajd_benefit_optimizer <task_id> $(date +%Y-%m-%d)
```

**ì¼ë°˜ì ì¸ í•´ê²°ì±…**:
```bash
# 1. ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
ls -la data/offers/
ls -la data/contracts/

# 2. ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
chmod -R 755 data/

# 3. SQLite íŒŒì¼ ê¶Œí•œ
chmod 666 data/ajd.db  # íŒŒì¼ì´ ìˆëŠ” ê²½ìš°
```

#### XCom ë°ì´í„° ì „ì†¡ ì˜¤ë¥˜
**ì¦ìƒ**: `KeyError: 'offers_raw'` ë˜ëŠ” XCom í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ

**í•´ê²°ì±…**:
```bash
# 1. XCom ë°ì´í„° í™•ì¸ (Airflow UI > Admin > XComs)
# 2. ì´ì „ íƒœìŠ¤í¬ ì„±ê³µ ì—¬ë¶€ í™•ì¸
airflow tasks state ajd_benefit_optimizer extract_offers $(date +%Y-%m-%d)

# 3. íƒœìŠ¤í¬ ì˜ì¡´ì„± ì¬í™•ì¸
airflow dags show ajd_benefit_optimizer
```

### 3ï¸âƒ£ í™˜ê²½ ê´€ë ¨ ë¬¸ì œ

#### ê°€ìƒí™˜ê²½ ë¬¸ì œ
**ì¦ìƒ**: íŒ¨í‚¤ì§€ import ì˜¤ë¥˜ ë˜ëŠ” Python ë²„ì „ ë¶ˆì¼ì¹˜

**í•´ê²°ì±…**:
```bash
# 1. ê°€ìƒí™˜ê²½ ì¬í™œì„±í™”
source .venv/bin/activate

# 2. Python ê²½ë¡œ í™•ì¸
which python
python --version

# 3. íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜
uv pip install --force-reinstall apache-airflow pandas sqlalchemy

# 4. ê°€ìƒí™˜ê²½ ì¬ìƒì„± (í•„ìš”ì‹œ)
rm -rf .venv
uv venv -p 3.11 .venv
source .venv/bin/activate
```

#### í¬íŠ¸ ì¶©ëŒ ë¬¸ì œ
**ì¦ìƒ**: `OSError: [Errno 98] Address already in use`

**í•´ê²°ì±…**:
```bash
# 1. í¬íŠ¸ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ í™•ì¸
netstat -tlnp | grep :8080
lsof -i :8080

# 2. í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>

# 3. Airflow í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
pkill -f airflow

# 4. ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©
airflow webserver --port 8081
```

### 4ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ë¬¸ì œ

#### SQLite íŒŒì¼ ìƒì„± ì•ˆë¨
**ì¦ìƒ**: `data/ajd.db` íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ

**í•´ê²°ì±…**:
```bash
# 1. ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
mkdir -p data

# 2. ê¶Œí•œ í™•ì¸
chmod 755 data/

# 3. ìˆ˜ë™ í…Œì´ë¸” ìƒì„±
cd $AIRFLOW_HOME
python -c "
from dags.lib.io_utils import create_database_schema
create_database_schema('data/ajd.db')
print('í…Œì´ë¸” ìƒì„± ì™„ë£Œ!')
"

# 4. SQLite ì„¤ì¹˜ í™•ì¸
sqlite3 --version
```

#### SQLite ê¶Œí•œ ì˜¤ë¥˜
**ì¦ìƒ**: `PermissionError: [Errno 13] Permission denied`

**í•´ê²°ì±…**:
```bash
# 1. íŒŒì¼ ê¶Œí•œ ìˆ˜ì •
chmod 666 data/ajd.db

# 2. ë””ë ‰í† ë¦¬ ê¶Œí•œ ìˆ˜ì •
chmod 755 data/

# 3. ì†Œìœ ì í™•ì¸
ls -la data/ajd.db

# 4. ì†Œìœ ì ë³€ê²½ (í•„ìš”ì‹œ)
chown $USER:$USER data/ajd.db
```

### 5ï¸âƒ£ ë„¤íŠ¸ì›Œí¬ ë° ì ‘ì† ë¬¸ì œ

#### Airflow UI ì ‘ì† ì•ˆë¨
**ì¦ìƒ**: http://localhost:8080 ì ‘ì† ì‹¤íŒ¨

**í•´ê²°ì±…**:
```bash
# 1. ì›¹ì„œë²„ ì‹¤í–‰ ìƒíƒœ í™•ì¸
ps aux | grep airflow

# 2. ë¡œê·¸ í™•ì¸
tail -f logs/webserver/*.log

# 3. ë°©í™”ë²½ í™•ì¸ (WSL)
# Windows ë°©í™”ë²½ì—ì„œ 8080 í¬íŠ¸ í—ˆìš©

# 4. ì„œë¹„ìŠ¤ ì¬ì‹œì‘
pkill -f "airflow webserver"
airflow webserver --port 8080 &
```

#### WSL ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ
**ì¦ìƒ**: WSLì—ì„œ localhost ì ‘ì† ì•ˆë¨

**í•´ê²°ì±…**:
```bash
# 1. WSL IP í™•ì¸
ip addr show eth0

# 2. Windowsì—ì„œ WSL IPë¡œ ì ‘ì†
# http://<WSL_IP>:8080

# 3. í¬íŠ¸ í¬ì›Œë”© ì„¤ì • (PowerShell ê´€ë¦¬ì ê¶Œí•œ)
netsh interface portproxy add v4tov4 listenport=8080 listenaddress=0.0.0.0 connectport=8080 connectaddress=<WSL_IP>
```

### 6ï¸âƒ£ ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œ

#### ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼
**ì¦ìƒ**: íƒœìŠ¤í¬ê°€ SLA ì‹œê°„(10ë¶„) ë‚´ì— ì™„ë£Œë˜ì§€ ì•ŠìŒ

**í•´ê²°ì±…**:
```bash
# 1. ë°ì´í„° í¬ê¸° í™•ì¸
wc -l data/offers/*.json
wc -l data/contracts/*.json

# 2. ì‹¤í–‰ ì‹œê°„ ì œí•œ ëŠ˜ë¦¬ê¸° (dags/ajd_benefit_optimizer.py ìˆ˜ì •)
'execution_timeout': timedelta(minutes=15),
'sla': timedelta(minutes=20)

# 3. ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
top
free -h
df -h
```

#### ë©”ëª¨ë¦¬ ë¶€ì¡±
**ì¦ìƒ**: `MemoryError` ë˜ëŠ” ì‹œìŠ¤í…œ ëŠë ¤ì§

**í•´ê²°ì±…**:
```bash
# 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
free -h
ps aux --sort=-%mem | head

# 2. ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
pkill -f "example_"  # Airflow ì˜ˆì œ DAGë“¤

# 3. ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸° (ì½”ë“œ ìˆ˜ì •)
# DataFrame ì²˜ë¦¬ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë³€ê²½
```

## ğŸ”§ ë””ë²„ê¹… ë„êµ¬ ë° ëª…ë ¹ì–´

### ìœ ìš©í•œ ë””ë²„ê¹… ëª…ë ¹ì–´
```bash
# 1. ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ
airflow version
airflow config list
airflow connections list

# 2. DAG ìƒíƒœ í™•ì¸
airflow dags list
airflow dags show ajd_benefit_optimizer
airflow dags state ajd_benefit_optimizer $(date +%Y-%m-%d)

# 3. íƒœìŠ¤í¬ ìƒíƒœ í™•ì¸
airflow tasks list ajd_benefit_optimizer
airflow tasks state ajd_benefit_optimizer <task_id> $(date +%Y-%m-%d)

# 4. ë¡œê·¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
tail -f logs/scheduler/latest/*.log
tail -f logs/dag_id/task_id/execution_date/*.log
```

### í™˜ê²½ ì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸
```bash
# 1. ê¸°ë³¸ í™˜ê²½
echo "AIRFLOW_HOME: $AIRFLOW_HOME"
echo "PYTHONPATH: $PYTHONPATH"
which python
python --version

# 2. íŒŒì¼ êµ¬ì¡°
ls -la $AIRFLOW_HOME/dags/
ls -la $AIRFLOW_HOME/dags/lib/
ls -la $AIRFLOW_HOME/data/

# 3. ê¶Œí•œ í™•ì¸
ls -la $AIRFLOW_HOME/dags/ajd_benefit_optimizer.py
ls -la $AIRFLOW_HOME/data/

# 4. í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep airflow
netstat -tlnp | grep 8080
```

## ğŸ“ ì§€ì› ë° ì¶”ê°€ ìë£Œ

### ë¡œê·¸ ìœ„ì¹˜
- **DAG ì‹¤í–‰ ë¡œê·¸**: `logs/ajd_benefit_optimizer/`
- **ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œê·¸**: `logs/scheduler/`
- **ì›¹ì„œë²„ ë¡œê·¸**: `logs/webserver/`

### ì„¤ì • íŒŒì¼
- **Airflow ì„¤ì •**: `airflow.cfg`
- **DAG ì„¤ì •**: `dags/ajd_benefit_optimizer.py`
- **ì˜ì¡´ì„±**: `requirements.txt`

### ì°¸ê³  ë¬¸ì„œ
- [Apache Airflow ê³µì‹ ë¬¸ì„œ](https://airflow.apache.org/docs/)
- [SQLite ê³µì‹ ë¬¸ì„œ](https://sqlite.org/docs.html)
- [pandas ê³µì‹ ë¬¸ì„œ](https://pandas.pydata.org/docs/)

---
*ìµœì¢… ì—…ë°ì´íŠ¸: 2025-08-31*  
*ê²€ì¦ í™˜ê²½: WSL Ubuntu + Python 3.11 + Airflow 2.9.2*
